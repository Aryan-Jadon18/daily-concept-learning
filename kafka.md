Apache kafka was created by linkedin and donated to Apache foundation. It is used for even streaming. Event streaming here means variety of application.
Event -> Event created data -> data is collected -> sent to be processed -> data is analyzed -> analysis leads to biz decisions.

What is event streaming used for?
- to process payments and financial transactions in real time, such as in stock exchanges, banks and insurances.
- to track and monitor shipments, vehicles in real time, such as in logistics and  automotive industry.
- to continously capture and analyze sensor data from IoT devices or other equipment, such as in factories and wind parks.
- to collect and immediately react to customer data such as in retail, hotels etc..
- To monitor patients in hospital and predict possible treatments for timely recovery.
- to connect, store data from a company's different divisions.
- to serve as foundation for data platforms, event driven architectures and microservices.

Key -> To publish(write) and subscribe(read) to streams of events, including continous import/export of your data from other systems. -> store streams relaibly as long and you want -/. to process streams of events as they occur or retrosprectively.
